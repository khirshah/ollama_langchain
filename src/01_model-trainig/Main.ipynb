{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils  import * \n",
    "from langchain.llms import Ollama\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Loading orca-mini from Ollama\n",
    "llm = Ollama(model=\"orca-mini\", temperature=0)\n",
    "\n",
    "# Loading the Embedding Model\n",
    "embed = load_embedding_model(model_path=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and splitting the documents\n",
    "docs = load_pdf_data(file_path=\"./../../data/ml_book.pdf\")\n",
    "documents = split_docs(documents=docs)\n",
    "\n",
    "# creating vectorstore\n",
    "vectorstore = create_embeddings(documents, embed)\n",
    "\n",
    "# converting vectorstore to a retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the prompt from the template which we created before\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Creating the chain\n",
    "chain = load_qa_chain(retriever, llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random Forest is an ensemble learning technique that involves building multiple decision trees and\n",
      "combining their predictions to improve accuracy. It is a popular method used in machine learning and\n",
      "data mining. Each tree in a Random Forest is grown randomly, with the number of splits (i.e., the\n",
      "number of features used for splitting) chosen randomly from a fixed set of possible values. This\n",
      "randomization helps to reduce overfitting and increase generalization performance. Random Forests\n",
      "have been found to be effective in classification and regression tasks, and are known for their\n",
      "ability to handle high-dimensional data and complex relationships between variables.\n"
     ]
    }
   ],
   "source": [
    "get_response(\"What is random forest?\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A voting classifier is a type of machine learning algorithm that predicts the class of a given\n",
      "input data point based on the majority vote of multiple classifiers. In other words, it takes the\n",
      "predictions of several different classifiers and predicts the class that gets the most votes. This\n",
      "method is often used to improve the accuracy of machine learning models by using the diversity of\n",
      "different classifiers to make more accurate predictions. The hard voting classifier is a specific\n",
      "type of voting classifier that achieves high accuracy by aggregating the predictions of multiple\n",
      "weak learners.\n"
     ]
    }
   ],
   "source": [
    "get_response(\"What is Voting Classifier?\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Voting classifiers and Random Forests are two different approaches to creating an ensemble of\n",
      "classifiers.   Voting classifiers use majority vote to predict the class that receives the most\n",
      "votes from the classifiers in the ensemble. This approach is based on the idea that the majority\n",
      "opinion is likely to be correct, and by aggregating the predictions of multiple classifiers, voting\n",
      "can help reduce overfitting and improve the accuracy of the final prediction.   On the other hand,\n",
      "Random Forests are an ensemble learning technique that use decision trees as base classifiers. In\n",
      "this approach, a random subset of the features is used to create a Decision Tree Classifier (DTC) in\n",
      "each iteration of the training process. The final prediction is made by aggregating the predictions\n",
      "of all the DTCs in the forest. Random Forests are known for their ability to handle large datasets\n",
      "and complex decision boundaries, making them a popular choice for many applications.   In summary,\n",
      "voting classifiers use majority vote to predict the class that receives the most votes from the\n",
      "classifiers in the ensemble, while Random Forests use decision trees as base classifiers and make\n",
      "final predictions by aggregating the predictions of all the DTCs in the forest.\n"
     ]
    }
   ],
   "source": [
    "get_response(\"What is the difference between voting classifier and random forest?\", chain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
