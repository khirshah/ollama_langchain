{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import *\n",
    "from langchain.llms import Ollama\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Loading orca-mini from Ollama\n",
    "llm = Ollama(model=\"orca-mini\", temperature=0)\n",
    "\n",
    "# Loading the Embedding Model\n",
    "embed = load_embedding_model(model_path=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and splitting the documents\n",
    "docs = load_pdf_data(file_path=\"./../../data/ml_book.pdf\")\n",
    "documents = split_docs(documents=docs)\n",
    "\n",
    "# creating vectorstore\n",
    "vectorstore = create_embeddings(documents, embed)\n",
    "\n",
    "# converting vectorstore to a retriever\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the prompt from the template which we created before\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Creating the chain\n",
    "chain = load_qa_chain(retriever, llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Random Forest is an ensemble learning technique that involves building multiple decision trees and\n",
      "combining their predictions to improve accuracy. It is a popular method used in machine learning and\n",
      "data mining. Each tree in a Random Forest is grown randomly, with the number of splits (i.e., the\n",
      "number of features used for splitting) chosen randomly from a fixed set of possible values. This\n",
      "randomization helps to reduce overfitting and increase generalization performance. Random Forests\n",
      "have been found to be effective in classification and regression tasks, and are known for their\n",
      "ability to handle high-dimensional data and complex relationships between variables.\n"
     ]
    }
   ],
   "source": [
    "get_response(\"What is random forest?\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3548, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_37781/839196188.py\", line 1, in <module>\n",
      "    get_response(\"What is Voting Classifier?\", chain)\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/src/01_model-trainig/utils.py\", line 99, in get_response\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/chains/base.py\", line 310, in __call__\n",
      "    raise e\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/chains/base.py\", line 304, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/chains/retrieval_qa/base.py\", line 139, in _call\n",
      "    answer = self.combine_documents_chain.run(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/chains/base.py\", line 510, in run\n",
      "    return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/chains/base.py\", line 310, in __call__\n",
      "    raise e\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/chains/base.py\", line 304, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/chains/combine_documents/base.py\", line 122, in _call\n",
      "    output, extra_return_dict = self.combine_docs(\n",
      "                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/chains/combine_documents/stuff.py\", line 171, in combine_docs\n",
      "    return self.llm_chain.predict(callbacks=callbacks, **inputs), {}\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/chains/llm.py\", line 298, in predict\n",
      "    return self(kwargs, callbacks=callbacks)[self.output_key]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/chains/base.py\", line 310, in __call__\n",
      "    raise e\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/chains/base.py\", line 304, in __call__\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/chains/llm.py\", line 108, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/chains/llm.py\", line 120, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/llms/base.py\", line 507, in generate_prompt\n",
      "    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/llms/base.py\", line 656, in generate\n",
      "    output = self._generate_helper(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/llms/base.py\", line 544, in _generate_helper\n",
      "    raise e\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/llms/base.py\", line 531, in _generate_helper\n",
      "    self._generate(\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/llms/ollama.py\", line 242, in _generate\n",
      "    final_chunk = super()._stream_with_aggregation(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/llms/ollama.py\", line 178, in _stream_with_aggregation\n",
      "    for stream_resp in self._create_stream(prompt, stop, **kwargs):\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/langchain/llms/ollama.py\", line 154, in _create_stream\n",
      "    response = requests.post(\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/requests/api.py\", line 115, in post\n",
      "    return request(\"post\", url, data=data, json=json, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/requests/api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/requests/sessions.py\", line 725, in send\n",
      "    history = [resp for resp in gen]\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/requests/sessions.py\", line 725, in <listcomp>\n",
      "    history = [resp for resp in gen]\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/requests/sessions.py\", line 266, in resolve_redirects\n",
      "    resp = self.send(\n",
      "           ^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 790, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 536, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/urllib3/connection.py\", line 461, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/miniconda3/lib/python3.11/http/client.py\", line 1378, in getresponse\n",
      "    response.begin()\n",
      "  File \"/home/agi/miniconda3/lib/python3.11/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/miniconda3/lib/python3.11/http/client.py\", line 279, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/miniconda3/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2142, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/home/agi/WORK/ai/repos/ollama_langchain/python_env/lib/python3.11/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "get_response(\"What is Voting Classifier?\", chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'What is the difference between voting classifier and random forest?', 'result': ' Voting classifiers and Random Forests are two different approaches to creating an ensemble of classifiers. \\n\\nVoting classifiers use majority vote to predict the class that receives the most votes from the classifiers in the ensemble. This approach is based on the idea that the majority opinion is likely to be correct, and by aggregating the predictions of multiple classifiers, voting can help reduce overfitting and improve the accuracy of the final prediction. \\n\\nOn the other hand, Random Forests are an ensemble learning technique that use decision trees as base classifiers. In this approach, a random subset of the features is used to create a Decision Tree Classifier (DTC) in each iteration of the training process. The final prediction is made by aggregating the predictions of all the DTCs in the forest. Random Forests are known for their ability to handle large datasets and complex decision boundaries, making them a popular choice for many applications. \\n\\nIn summary, voting classifiers use majority vote to predict the class that receives the most votes from the classifiers in the ensemble, while Random Forests use decision trees as base classifiers and make final predictions by aggregating the predictions of all the DTCs in the forest.', 'source_documents': [Document(page_content='Voting Classifiers\\nSuppose you have trained a few classifiers, each one achieving about 80% accuracy.\\nYou may have a Logistic Regression classifier, an SVM classifier, a Random Forest\\nclassifier, a K-Nearest Neighbors classifier, and perhaps a few more (see Figure 7-1).\\nFigure 7-1. Training diverse classifiers\\nA very simple way to create an even better classifier is to aggregate the predictions of\\neach classifier and predict the class that gets the most votes. This majority-vote classi‐\\nfier is called a hard voting classifier (see Figure 7-2).\\nFigure 7-2. Hard voting classifier predictions\\n192 \\n| \\nChapter 7: Ensemble Learning and Random Forests', metadata={'source': 'ml_book.pdf', 'file_path': 'ml_book.pdf', 'page': 217, 'total_pages': 510, 'format': 'PDF 1.5', 'title': 'Hands-On Machine Learning with Scikit-Learn and TensorFlow', 'author': '', 'subject': '', 'keywords': '', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'producer': 'iLovePDF', 'creationDate': \"D:20190507155131+00'00'\", 'modDate': 'D:20231020021301Z', 'trapped': ''}), Document(page_content='9 “Random Decision Forests,” T. Ho (1995).\\n10 The BaggingClassifier class remains useful if you want a bag of something other than Decision Trees.\\n11 There are a few notable exceptions: splitter is absent (forced to \"random\"), presort is absent (forced to\\nFalse), max_samples is absent (forced to 1.0), and base_estimator is absent (forced to DecisionTreeClassi\\nfier with the provided hyperparameters).\\nSampling features results in even more predictor diversity, trading a bit more bias for\\na lower variance.\\nRandom Forests\\nAs we have discussed, a Random Forest9 is an ensemble of Decision Trees, generally\\ntrained via the bagging method (or sometimes pasting), typically with max_samples\\nset to the size of the training set. Instead of building a BaggingClassifier and pass‐\\ning it a DecisionTreeClassifier, you can instead use the RandomForestClassifier\\nclass, which is more convenient and optimized for Decision Trees10 (similarly, there is', metadata={'source': 'ml_book.pdf', 'file_path': 'ml_book.pdf', 'page': 224, 'total_pages': 510, 'format': 'PDF 1.5', 'title': 'Hands-On Machine Learning with Scikit-Learn and TensorFlow', 'author': '', 'subject': '', 'keywords': '', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'producer': 'iLovePDF', 'creationDate': \"D:20190507155131+00'00'\", 'modDate': 'D:20231020021301Z', 'trapped': ''}), Document(page_content='generally yielding an overall better model. The following BaggingClassifier is\\nroughly equivalent to the previous RandomForestClassifier:\\nbag_clf = BaggingClassifier(\\n    DecisionTreeClassifier(splitter=\"random\", max_leaf_nodes=16),\\n    n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1)\\nRandom Forests \\n| \\n199', metadata={'source': 'ml_book.pdf', 'file_path': 'ml_book.pdf', 'page': 224, 'total_pages': 510, 'format': 'PDF 1.5', 'title': 'Hands-On Machine Learning with Scikit-Learn and TensorFlow', 'author': '', 'subject': '', 'keywords': '', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'producer': 'iLovePDF', 'creationDate': \"D:20190507155131+00'00'\", 'modDate': 'D:20231020021301Z', 'trapped': ''}), Document(page_content='classifiers for an image, and the target is the image’s class. Train a classifier on\\nthis new training set. Congratulations, you have just trained a blender, and\\ntogether with the classifiers they form a stacking ensemble! Now let’s evaluate the\\nensemble on the test set. For each image in the test set, make predictions with all\\nyour classifiers, then feed the predictions to the blender to get the ensemble’s pre‐\\ndictions. How does it compare to the voting classifier you trained earlier?\\nSolutions to these exercises are available in ???.\\n214 \\n| \\nChapter 7: Ensemble Learning and Random Forests', metadata={'source': 'ml_book.pdf', 'file_path': 'ml_book.pdf', 'page': 239, 'total_pages': 510, 'format': 'PDF 1.5', 'title': 'Hands-On Machine Learning with Scikit-Learn and TensorFlow', 'author': '', 'subject': '', 'keywords': '', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'producer': 'iLovePDF', 'creationDate': \"D:20190507155131+00'00'\", 'modDate': 'D:20231020021301Z', 'trapped': ''})]}\n"
     ]
    }
   ],
   "source": [
    "get_response(\"What is the difference between voting classifier and random forest?\", chain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
